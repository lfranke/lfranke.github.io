<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Linus Franke</title>

  <meta name="author" content="Linus Franke">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:60%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Linus Franke
                  </p>
                  <p>I'm a PhD Student under the supervision of <a
                      href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a> at the <a
                      href="https://www.lgdv.tf.fau.de/">Chair of Visual Computing</a> of the
                    Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:">linus (dot) franke (at) fau (dot) de</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?hl=en&user=WwjWM6UAAAAJ">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://bsky.app/profile/linusfranke.bsky.social">Bluesky</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/_linus_franke">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://github.com/lfranke/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/dsc04160d_klein.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/dsc04160d_klein.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    Research interest in computer graphics, perceptual rendering, computer vision and machine learning.
                    Currently primar focus in neural rendering and novel view synthesis. Representative papers are <span
                      class="highlight">highlighted</span>.

                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="vrsplatting_stop()" onmouseover="vrsplatting_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='vrsplatting_video' style="transition: opacity 0.4s">
                      <video width=100% height=100% muted autoplay loop>
                        <source src="images/vrsplatting_teaser_website.mp4" type="video/mp4">Your browser does not
                        support the video tag.
                      </video>
                    </div>
                    <img src='images/vrsplatting_teaser.jpg' id='vrsplatting_image' width="160"
                      style="transition: opacity 0.4s">
                  </div>
                  <script type="text/javascript">
                    function vrsplatting_start() {
                      document.getElementById('vrsplatting_image').style.opacity = "0";
                      document.getElementById('vrsplatting_video').style.opacity = "1";
                    }

                    function vrsplatting_stop() {
                      document.getElementById('vrsplatting_video').style.opacity = "0";
                      document.getElementById('vrsplatting_image').style.opacity = "1";
                    }
                    vrsplatting_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="vr_splatting">
                    <span class="papertitle">VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting
                      and Neural Points</span>
                  </a>
                  <br>
                  <strong>Linus Franke</strong>,
                  Laura Fink,
                  Marc Stamminger
                  <br>
                  <em> i3D 2025 (Proceedings of the ACM on Computer Graphics and Interactive Techniques)</em>, 2025
                  <br>
                  <a href="https://lfranke.github.io/vr_splatting">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2410.17932">paper</a>
                  <!--     /
                <a href="https://youtu.be/Nw4A1tIcErQ">video</a>       -->
                  /
                  <a href="https://github.com/lfranke/vr_splatting">code</a>

                  <p></p>
                  <p>
                    Foveated radiance field rendering with smooth Gaussian peripheral and neural point splats for crisp
                    foveal rendering.
                  </p>
                </td>
              </tr>

              <!-- INPC -->
              <tr onmouseout="inpc_stop()" onmouseover="inpc_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='inpc_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/inpc_video.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/inpc_image.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function inpc_start() {
                      document.getElementById('inpc_image').style.opacity = "1";
                    }

                    function inpc_stop() {
                      document.getElementById('inpc_image').style.opacity = "0";
                    }
                    inpc_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://fhahlbohm.github.io/inpc">
                    <span class="papertitle">INPC: Implicit Neural Point Clouds for Radiance Field Rendering</span>
                  </a>
                  <br>
                  Florian Hahlbohm,
                  <strong>Linus Franke</strong>,
                  Moritz Kappel,
                  Susana Castillo,
                  Martin Eisemann,
                  Marc Stamminger,
                  Marcus Magnor
                  <br>
                  <em>3DV</em>, 2025 (Oral)
                  <br>
                  <a href="https://fhahlbohm.github.io/inpc">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2403.16862">paper</a>
                  /
                  <a href="https://youtu.be/UqDlS3QGNMo">video</a>
                  /
                  <a href="">code</a>
                  <p></p>
                  <p>
                    Implicit volume-based scene reconstruction combined with point rendering for high detail novel-view
                    synthesis.
                  </p>
                </td>
              </tr>

              <!-- HTGS -->
              <tr onmouseout="htgs_stop()" onmouseover="htgs_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='htgs_video' style="transition: opacity 0.4s">
                      <video width=100% height=100% muted autoplay loop>
                        <source src="images/htgs_video.mp4" type="video/mp4">Your browser does not support the video
                        tag.
                      </video>
                    </div>
                    <img src='images/htgs_image.jpg' id='htgs_image' width="160" style="transition: opacity 0.4s">
                  </div>
                  <script type="text/javascript">
                    function htgs_start() {
                      document.getElementById('htgs_image').style.opacity = "0";
                      document.getElementById('htgs_video').style.opacity = "1";
                    }

                    function htgs_stop() {
                      document.getElementById('htgs_video').style.opacity = "0";
                      document.getElementById('htgs_image').style.opacity = "1";
                    }
                    htgs_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://fhahlbohm.github.io/htgs/">
                    <span class="papertitle">Efficient Perspective-Correct 3D Gaussian Splatting Using Hybrid
                      Transparency</span>
                  </a>
                  <br>
                  Florian Hahlbohm,
                  Fabian Friederichs,
                  Tim Weyrich,
                  <strong>Linus Franke</strong>,
                  Moritz Kappel,
                  Susana Castillo,
                  Marc Stamminger,
                  Martin Eisemann,
                  Marcus Magnor
                  <br>
                  <em>Eurographics (Computer Graphics Forum)</em>, 2025
                  <br>
                  <a href="https://fhahlbohm.github.io/htgs/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2410.08129">paper</a>
                  <!--          /-->
                  <!--          <a href="TODO">code</a>-->
                  <p></p>
                  <p>
                    A perspective-correct and view-consistent approach for 3D Gaussian splatting accelerated through
                    hybrid transparency.
                  </p>
                </td>
              </tr>




              <tr onmouseout="ref_depth_stop()" onmouseover="ref_depth_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='ref_depth_image'><video height=100% width=100% muted autoplay loop>
                        <source src="images/ref_depth_teaser.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img style="vertical-align: bottom;" translate=12px src='images/ref_depth_teaser.jpg' width="160"
                      height="70">
                  </div>
                  <script type="text/javascript">
                    function ref_depth_start() {
                      document.getElementById('ref_depth_image').style.opacity = "1";
                    }
                    function ref_depth_stop() {
                      document.getElementById('ref_depth_image').style.opacity = "0";
                    }
                    ref_depth_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lorafib.github.io/ref_depth">
                    <span class="papertitle">Refinement of Monocular Depth Maps via Multi-View Differentiable
                      Rendering</span>
                  </a>
                  <br>
                  Laura Fink, <strong>Linus Franke</strong>, Joachim Keinert, Marc Stamminger
                  <br>
                  <em>arXiv</em>, 2024
                  <br>
                  <a href="https://lorafib.github.io/ref_depth">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2410.03861">paper</a>
                  /
                  <a href="https://github.com/lorafib/ref_depth">code</a>
                  <!-- /
                <a href="https://youtu.be/TODO">video</a> -->
                  <p></p>
                  <p>Dense and multi-view consitent depth maps optimized from an monoscopically estimated
                    initialization.</p>
                </td>
              </tr>




              <tr onmouseout="trips_stop()" onmouseover="trips_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:bottom">
                  <div class="one">
                    <div class="two" id='trips_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/trips_teaser_website.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img style="vertical-align: bottom;" translate=12px src='images/trips_teaser.jpg' width="160"
                      height="100">
                  </div>
                  <script type="text/javascript">
                    function trips_start() {
                      document.getElementById('trips_image').style.opacity = "1";
                    }
                    function trips_stop() {
                      document.getElementById('trips_image').style.opacity = "0";
                    }
                    trips_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="trips">
                    <span class="papertitle">TRIPS: Trilinear Point Splatting for Real-Time Radiance Field
                      Rendering</span>
                  </a>
                  <br>
                  <strong>Linus Franke</strong>,
                  Darius Rückert,
                  Laura Fink,
                  Marc Stamminger
                  <br>
                  <em>Eurographics (Computer Graphics Forum)</em>, 2024
                  <br>
                  <a href="https://lfranke.github.io/trips">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2401.06003">paper</a>
                  /
                  <a href="https://youtu.be/Nw4A1tIcErQ">video</a>
                  /
                  <a href="https://github.com/lfranke/TRIPS">code</a>
                  <p></p>
                  <p>
                    Rendering and optimizing neural point clouds via trilinear point splatting and tiny neural networks
                    for novel-view synthesis.
                  </p>
                </td>
              </tr>





              <tr onmouseout="vet_stop()" onmouseover="vet_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:bottom">
                  <div class="one">
                    <div class="two" id='vet_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/vet_teaser_website.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img style="vertical-align: bottom;" translate=12px src='images/vet_teaser_res.jpeg' width="160"
                      height="100">
                  </div>
                  <script type="text/javascript">
                    function vet_start() {
                      document.getElementById('vet_image').style.opacity = "1";
                    }
                    function vet_stop() {
                      document.getElementById('vet_image').style.opacity = "0";
                    }
                    vet_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="vet">
                    <span class="papertitle">VET: Visual Error Tomography for Point Cloud Completion and High-Quality
                      Neural Rendering</span>
                  </a>
                  <br>
                  <strong>Linus Franke</strong>,
                  Darius Rückert,
                  Laura Fink,
                  Matthias Innmann,
                  Marc Stamminger
                  <br>
                  <em>SIGGRAPH Asia</em>, 2023
                  <br>
                  <a href="https://lfranke.github.io/vet">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2311.04634">paper</a>
                  /
                  <a href="https://youtu.be/adH6GyqC4Jk">video</a>
                  /
                  <a href="https://github.com/lfranke/VET">code</a>
                  /
                  <a href="https://youtu.be/dMsD_xXOEKA?feature=shared&t=1933">fast forward</a>
                  <p></p>
                  <p>
                    Improving point-based novel view synthesis quality by completing point cloud with 3D error volumes
                    from 2D error maps.
                  </p>
                </td>
              </tr>


              <tr onmouseout="inovis_stop()" onmouseover="inovis_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='inovis_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/inovis_teaser_vid.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img style="vertical-align: bottom;" translate=12px src='images/inovis_teaser.jpg' width="160"
                      height="100">
                  </div>
                  <script type="text/javascript">
                    function inovis_start() {
                      document.getElementById('inovis_image').style.opacity = "1";
                    }
                    function inovis_stop() {
                      document.getElementById('inovis_image').style.opacity = "0";
                    }
                    inovis_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a
                    href="https://reality.tf.fau.de/publications/2023/harrerfranke2023inovis/harrerfranke2023inovis.html">
                    <span class="papertitle">Inovis: Instant Novel View Synthesis</span>
                  </a>
                  <br>
                  Mathias Harrer*
                  <strong>Linus Franke*</strong>,
                  Laura Fink,
                  Marc Stamminger,
                  Tim Weyrich
                  <br>
                  <em>SIGGRAPH Asia</em>, 2023
                  <br>
                  <a
                    href="https://reality.tf.fau.de/publications/2023/harrerfranke2023inovis/harrerfranke2023inovis.html">project
                    page</a>
                  /
                  <a
                    href="https://reality.tf.fau.de/publications/2023/harrerfranke2023inovis/harrerfranke2023inovis.pdf">paper</a>
                  /
                  <a
                    href="https://reality.tf.fau.de/publications/2023/harrerfranke2023inovis/harrerfranke2023inovis.mp4">video</a>
                  /
                  <a href="https://github.com/mharrer97/inovis">code</a>
                  <p></p>
                  <p>
                    Point-based novel view synthesis without per scene preprocessing or training using neural image
                    based rendering. (*) Denotes equal contribution.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <img src='images/livenvs_teaser.jpg' width="160" height="100">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lorafib.github.io/livenvs/">
                    <span class="papertitle">LiveNVS: Neural View Synthesis on Live RGB-D Streams</span>
                  </a>
                  <br>
                  Laura Fink, Darius Rückert, <strong>Linus Franke</strong>, Joachim Keinert, Marc Stamminger
                  <br>
                  <em>SIGGRAPH Asia</em>, 2023
                  <br>
                  <a href="https://lorafib.github.io/livenvs/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2311.16668">paper</a>
                  /
                  <a href="https://youtu.be/aMbE5WAgD2k">video</a>
                  /
                  <a href="https://github.com/Fraunhofer-IIS/livenvs">code</a>
                  <p></p>
                  <p>Novel view synthesis on live RGB-D streams with feedback during capturing, robust to slam loop
                    closures.</p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <img src='images/lf_proj_teaser.jpeg' width="160" height="100">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dl.acm.org/doi/pdf/10.1145/3585498">
                    <span class="papertitle">Efficient Rendering for Light Field Displays using Tailored Projective
                      Mappings</span>
                  </a>
                  <br>
                  Laura Fink, Svenja Strobel, <strong>Linus Franke</strong>, Marc Stamminger
                  <br>
                  <em>i3D 2023 (Proceedings of the ACM on Computer Graphics and Interactive Techniques)</em>, 2023
                  <br>
                  <a href="https://dl.acm.org/doi/pdf/10.1145/3585498">paper</a>
                  /
                  <a href="https://youtu.be/ntYMnq3-VcA?feature=shared&t=24">presentation</a>
                  /
                  <a href="https://github.com/lorafib/projs-for-lfd-rendering">code</a>
                  <p></p>
                  <p>Rendering only relevant fragments for parallax-based light field displays through device-tailored
                    projection matrices.</p>
                </td>
              </tr>

              <tr>


              <tr onmouseout="adop_stop()" onmouseover="adop_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:bottom">
                  <div class="one">
                    <div class="two" id='adop_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/adop_teaser.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img style="vertical-align: bottom;" translate=12px src='images/adop_teaser.jpg' width="160"
                      height="100">
                  </div>
                  <script type="text/javascript">
                    function adop_start() {
                      document.getElementById('adop_image').style.opacity = "1";
                    }
                    function adop_stop() {
                      document.getElementById('adop_image').style.opacity = "0";
                    }
                    adop_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/darglein/ADOP">
                    <span class="papertitle">ADOP: Approximate Differentiable One-pixel Point Rendering</span>
                  </a>
                  <br>
                  Darius Rückert, <strong>Linus Franke</strong>, Marc Stamminger
                  <br>
                  <em>SIGGRAPH (TOG)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2110.06635">paper</a>
                  /
                  <a href="https://youtu.be/WJRyu1JUtVw">video</a>
                  /
                  <a href="https://github.com/darglein/ADOP">code</a>
                  <p></p>


                  <p></p>
                  <p>Point-based differentiable one-pixel point rendering for automatic scene calibration and
                    high-quality novel view synthesis.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:top" bgcolor="#ffffd0">
                  <img src='images/tfov_teaser.jpg' width="160" height="100">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle" bgcolor="#ffffd0">
                  <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14176">
                    <span class="papertitle">Time‐Warped Foveated Rendering for Virtual Reality Headsets</span>
                  </a>
                  <br>
                  <strong>Linus Franke</strong>, Laura Fink, Jana Martschinke, Kai Selgrad, Marc Stamminger
                  <br>
                  <em>Computer Graphics Forum</em>, 2021 (Oral presentation at Eurographics 2021)
                  <br>
                  <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14176">paper</a>
                  /
                  <a href="https://youtu.be/tdrjMvAlZFc">presentation</a>
                  /
                  <a
                    href="https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2Fcgf.14176&file=cgf14176-sup-0001-SuppMat.pdf">supplemental
                    material</a>
                  <p></p>
                  <p>Foveated Rendering via temporal forward reprojection for fast, imperceptible VR rendering.</p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <img src='images/mltdof_teaser.jpeg' width="160" height="100">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dl.acm.org/doi/10.1145/3203200">
                    <span class="papertitle"> Multi-Layer Depth of Field Rendering with Tiled Splatting </span>
                  </a>
                  <br>
                  <strong>Linus Franke</strong>, Nikolai Hofmann, Marc Stamminger, Kai Selgrad
                  <br>
                  <em> i3D 2018 (Proceedings of the ACM on Computer Graphics and Interactive Techniques)</em>, 2018
                  <br>
                  <a href="https://selgrad.org/publications/2018_i3d_FHSS.pdf">paper</a>
                  /
                  <a href="https://selgrad.org/publications/2018_i3d_FHSS_suppl.pdf">supplemental material</a>
                  <p></p>
                  <p>A multi-layered depth of field method for solving partial occlusion in real-time rendering.</p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <img src='images/lier_case_study_teaser.jpeg' width="160" height="110">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://selgrad.org/publications/2016_els_LFSS.pdf">
                    <span class="papertitle">A Case Study in Implementation-Space Exploration</span>
                  </a>
                  <br>
                  Alexander Lier, <strong>Linus Franke</strong>, Marc Stamminger, Kai Selgrad
                  <br>
                  <em>Proceedings of the 9th European Lisp Symposium on European Lisp Symposium</em>, 2016
                  <br>
                  <a href="https://selgrad.org/publications/2016_els_LFSS.pdf">paper</a>
                  <p></p>
                  <p>Exploration of generative programming for efficient CUDA kernels in depth of field rendering.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <img src='images/tdof_poster_teaser.jpeg' width="160" height="90">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://diglib.eg.org/handle/10.2312/egp20161056">
                    <span class="papertitle">Tiled Depth of Field Splatting</span>
                  </a>
                  <br>
                  Kai Selgrad, <strong>Linus Franke</strong>, Marc Stamminger
                  <br>
                  <em>Eurographics Posters</em>, 2016
                  <br>
                  <a href="https://diglib.eg.org/bitstream/handle/10.2312/egp20161056/039-040.pdf">paper</a>
                  /
                  <a href="https://diglib.eg.org/bitstream/handle/10.2312/egp20161056/poster-a4.pdf">poster</a>
                  <p></p>
                  <p>Single-layer tiled splatting for depth of field rendering.</p>
                </td>
              </tr>


            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for his great <a
                      href="https://github.com/jonbarron/jonbarron_website">template</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>