
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points</title>

    <meta name="description" content="In this paper, we propose a novel foveated rendering approach for VR radiance field rendering via Gaussian and neural point splatting." />
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://lfranke.github.io/vr_splatting/media/teaser_vr.jpg">
    <meta property="og:image:type" content="image/jpg">
    <!-- <meta property="og:video:width" content="750">
    <meta property="og:image:height" content="500"> -->
    <meta property="og:type" content="website" />
    <meta property="og:title" content="VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points" />
    <meta property="og:description" content="In this paper, we propose a novel foveated rendering approach for VR radiance field rendering via Gaussian and neural point splatting." />

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="https://lfranke.github.io/vr_splatting/" />
    <meta name="twitter:title" content="VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points" />
    <meta name="twitter:description" content="In this paper, we propose a novel foveated rendering approach for VR radiance field rendering via Gaussian and neural point splatting." />
    <meta name="twitter:image" content="https://lfranke.github.io/vr_splatting/media/teaser_vr.jpg" />


<!--
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
//-->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>

    <link rel="stylesheet" href="css/dics.min.css">
    <script src="js/dics.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', domReady);
        function domReady() {
            for (const e of document.querySelectorAll(".b-dics")) {
                new Dics({
                    container: e,
                    textPosition: "top"
                });
            }
        }
    </script>
</head>

<body>
    <div class="container" id="main">
        <a href="..">Back to my projects</a>
        <br><br>
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>VR-Splatting</b>: Foveated Radiance Field Rendering</br> via 3D Gaussian Splatting and Neural Points</br>
                
                <!-- <small>
                    Under review
                </small> -->
                <small>
                ArXiv
            </small>

            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a style="text-decoration:none" href="https://lfranke.github.io">
                            Linus Franke
                        </a>
                        <br>FAU Erlangen-Nürnberg<br> &zwnj;
                    </li>
                    <li>
                        <a style="text-decoration:none" href="https://lorafib.github.io">
                            Laura Fink
                        </a>
                        <br>FAU Erlangen-Nürnberg<br> &zwnj;
                    </li>
                    <li>
                        <a style="text-decoration:none" href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">
                            Marc Stamminger
                        </a>
                        <br>FAU Erlangen-Nürnberg
                        <br>  &zwnj;
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2410.17932">
                            <img src="media/paper_text.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="">
                            <img src="media/youtube_icon.png" height="60px">
                                <h4><strong>Video (coming soon)</strong></h4>
                            </a>
                        </li>
                         <li>
                            <a href="https://github.com/lfranke/vr_splatting">
                            <image src="media/github.png" height="60px">
                                <h4><strong>Code (coming soon)</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>




        <div class="row">


            <div class="col-md-8 col-md-offset-2">
                <br>
                <img src="media/teaser_vr_full.jpg" style="width:100%">
                <p class="text-justify">
                <br>
                    <h4>
                        Key Insights
                    </h4>
                <h5>

                    for Gaussian splatting [Kerbl and Kopanas et al. 2023] based VR rendering:
                </h5>

                    <p class="text-justify">
                        <ol>
                            <li>
                            VR requires very high (90Hz) framerates, thus only low number of Gaussians are possible as <b>performance decreases with number of primitives</b>.
                            </li>
                            <li>
                            Popping artifacts are distracting in VR, as such <b>costly per-pixel correct sorting of Gaussians is required</b>, limiting number of Gaussians even further.
                            </li>
                            <li>
                                Such Gaussian reconstructions are low-detail and smoothed, which makes them <b>perfect for peripheral rendering</b> in <b>foveated rendering</b>.
                            </li>
                            <li>
                                We can employ rendering modes such as <b>neural points</b> requiring convolutional neural network evaluation <b>(scaling cost per pixel)</b> for the very small <b>foveal region</b>.
                            </li>
                        </ol> 
                    </p>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="media/treehill_teaser_text.webm" type="video/webm" />
                </video>
                <p class="text-justify">
                    Teaser: Foveated rendering (<span style="color:red">red</span> fixation point) with neural points, periphery with low amounts of Gaussians. Resolution of 2016x2240 per eye.
                    
                </p>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                        Recent advances in novel view synthesis (NVS), particularly neural radiance fields (NeRF) and Gaussian splatting (3DGS), have demonstrated impressive results in photorealistic scene rendering. 
                        These techniques hold great potential for applications in virtual tourism and teleportation, where immersive realism is crucial. 
                        However, the <b>high-performance demands of virtual reality</b> (VR) systems present challenges in directly utilizing even such fast-to-render scene representations like 3DGS due to latency and computational constraints.
                </p>
                <p class="text-justify">
                        In this paper, we propose <b>foveated rendering</b> as a promising solution to these obstacles. 
                        We analyze state-of-the-art NVS methods with respect to their rendering performance and compatibility with the human visual system. 
                        Our approach introduces a novel foveated rendering approach for Virtual Reality, that leverages the <b>sharp, detailed output of neural point rendering for the foveal region</b>, fused with a <b>smooth rendering of 3DGS for the peripheral vision</b>.
                </p>        
                        Our evaluation confirms that perceived sharpness and detail-richness are increased by our approach compared to a standard VR-ready 3DGS configuration.
                        Our system meets the necessary performance requirements for real-time VR interactions, ultimately enhancing the user's immersive experience.
                    </p>        

            </div>
        </div>


        <br>

        <br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Motivation
                </h3>
                <img id="fov" src="media/motivation_plot.jpg" width="40%" class="center"> 
                <br>
                Gaussian rendering times increase drastically with number of splats, making <b>full 3D Gaussian Splatting in VR difficult</b>.<br>
                <br>
                <br>
                <img id="fov" src="media/foveated_teaser.jpg" width="30%" class="center"> 
                <br>
                Thus for efficient rendering, we want a <b>foveated</b> approach, where looked-at areas are rendered in high quality and peripheral areas have lower rendering quality.
                <br>
                The periphery is sensitive to flickering. Gaussians however are inherently smooth, even at low primitive counts, making <b>Gaussians perfect for peripheral rendering</b>.
                <br>
                <br>
                <img id="fov" src="media/3dgs_trips_gt.jpg" width="59%" class="center">   
                <br>
                In the small time budget for the <b>fovea</b>, we can use <b>neural point rendering</b> (via TRIPS [Franke et al. 2024]) for crisper details.

            </div>
        </div>
        <br><br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Pipeline
                </h3>
                <img id="test" src="media/pipeline.jpg" width="100%">  
                <br><br>
                Our method is as follows:
                <ol>
                <li>
                    A smooth color image and approximate depth map are rendered from a limited set of 3D Gaussians with a temporally stable sorting active.  
                </li>
                <li>   
                    Afterwards the eye tracking system is queried to construct a subfrustum via an adapted projection matrix covering only the foveal region.
                    We project a separate neural point cloud with the adapted matrix.
                    Points, occluded by the denser Gaussian splats, are culled against the approximate depth maps and the result is interpreted by a shallow convolutional neural network.
                </li>
                <li>
                    Eventually, we blend the peripheral color output and the foveal region using an egde-aware mask. 
                </li>
            </ol>
            The pipeline is trained end-to-end as a combined foveated representation.
            <br>
            <br>
                <img id="fov" src="media/combinefunc.jpg" width="50%" class="center">  
                Our combination function: An edge-aware mask blends peripheral and foveal renderings.

            </ol>
            </div>
        </div>
        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <h4>
                    SteamVR display mirroring
                </h4>
                    <video id="v0" width="100%" autoplay loop muted controls>
                        <source src="media/steamvr.webm" type="video/webm" />
                    </video>
                    Our pipeline runs in <b>90Hz</b> with full VR resolution of <b>2016x2240 pixels per eye</b>.
                    <h4>
                    User Study
                    </h4>
                    Two-alternative forced-choice (2AFC) between OURS and VR-GS, a Gaussian Splatting VR solution (few primitives). 
                    Five Scenes (Garden, Bicycle, Bonsai, Family, Playground), twelve participants (aged 22 to 30, four female, eight male), 20 trials each.
                    <br>
                    We observe a significantly higher ratio of participant <b>preferring OURS</b> to VRGS (~76% preferred OURS, SD=0.196).
                    Binomial testing showed  <b>significance</b> with p &lt; 0.005.

                  <br>
                  <br>
                  <h4>
                    Table
                    </h4>
                  <img id="fov" src="media/bigtable.jpg" width="100%">  
                  <br>
                  <br>
                  Quantitative metrics. JOD (Just-Objectionable-Difference) [Mantiuk et al. 2021] are computed with FovVideoVDP for an HTC Vive Pro in foveated mode for the full images. LPIPS, PSNR and SSIM metrics are evaluated for the foveal regions only.
                  <br>
                  <br>

                </div> 
            </div>
        <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Videos
            </h3>
            (<span style="color:red">red</span> fixation point)
                  <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="media/garden_text.webm" type="video/webm" />
                  </video>                  <br>
                  <br>
                  <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="media/gardengrass_text.webm" type="video/webm" />
                  </video>
                  <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="media/family_text.webm" type="video/webm" />
                  </video>
            </div>
        </div>
        <br>
        <br>
        <div class="row"></div>
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Training
                </h3>
                Timelapse of training.
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="media/training_only_lower.webm" type="video/webm" />
                </video>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-12 col-md-offset-0">
                    <textarea id="bibtex" class="form-control" readonly>
@article{franke2024vrsplatting,
    title={VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points},
    author={Linus Franke and Laura Fink and Marc Stamminger},
    journal={arXiv preprint arXiv:2410.17932},
    year = {2024}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>

                <p class="text-justify">
                Linus Franke was supported by the Bayerische Forschungsstiftung (Bavarian Research Foundation) AZ-1422-20 and the 5G innovation program of the German Federal Ministry for Digital and Transport under the funding code 165GU103B.
                <br>
                The authors gratefully acknowledge the scientific support and HPC resources provided by the National High Performance Computing Center  of the Friedrich-Alexander-Universität Erlangen-Nürnberg (NHR@FAU) under the project b162dc. NHR funding is provided by federal and Bavarian state authorities. NHR@FAU hardware is partially funded by the German Research Foundation (DFG) – 440719683. </p>
                <br>
                <br>
                

                <p class="text-justify">
                    The website template was adapted from <a href="https://lorafib.github.io/ref_depth">RefDepth</a>, who borrowed from  <a href="https://lfranke.github.io/vet">VET</a>, who borrowed from <a href="https://jonbarron.info/zipnerf/">Zip-NeRF</a>, who borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                    Image sliders are from <a href="https://bakedsdf.github.io/">BakedSDF</a>.
                </p>
            </div>
        </div>

    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                References
            </h3>
    <div class="content has-text-justified">
        <p>    
            [Kerbl and Kopanas 2023] Kerbl, B., Kopanas, G., Leimkühler, T., and Drettakis, G. 2023. "3D Gaussian splatting for real-time radiance field rendering". ACM Transactions on Graphics (ToG), 42(4).
        </p>
        <p>    
            [Franke 2024] Franke, L., Rückert, D., Fink, L., & Stamminger, M. (2024). TRIPS: Trilinear Point Splatting for Real‐Time Radiance Field Rendering. In Computer Graphics Forum.
        </p>
        <p>    
            [Mantiuk 2021] Mantiuk, R. K., Denes, G., Chapiro, A., Kaplanyan, A., Rufo, G., Bachy, R., Lian, T., & Patney, A. (2021). Fovvideovdp: A visible difference predictor for wide field-of-view video. ACM Transactions on Graphics (TOG), 40(4).
        </p>


      </div>
    </div>

</body>
</html>
